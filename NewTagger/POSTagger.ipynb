{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow_text as tf_text\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import json\r\n",
    "import FTokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "with open(\"D:/a-Code/Ignite Niek/foxPython/word_2_vec/data/new_vocabs_weights4.json\",\"r\",encoding=\"utf-8\") as f:\r\n",
    "    vocab_weights=json.load(f)\r\n",
    "len(vocab_weights)\r\n",
    "\r\n",
    "with open(\"D:/a-Code/Ignite Niek/foxPython/data/bi_grams.txt\",encoding=\"utf-8\") as f:\r\n",
    "    bi_gramtxt=f.read()\r\n",
    "bi_gram_list=[]\r\n",
    "for each in bi_gramtxt.split(\",\"):\r\n",
    "    each=each[:-1]\r\n",
    "    each=each[2:]\r\n",
    "    each=each.replace(\" \",\"_\")\r\n",
    "    bi_gram_list.append(each)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "with open(\"D:/a-Code/Ignite Niek/foxPython/data/vi_vtb-ud-train-dev.json\",\"r\",encoding=\"utf-8\") as f:\r\n",
    "    data=json.load(f)\r\n",
    "print(data[0][\"paragraphs\"][0][\"sentences\"][0][\"tokens\"])\r\n",
    "\r\n",
    "with open(\"D:/a-Code/Ignite Niek/foxPython/data/vi_vtb-ud-test.json\",\"r\",encoding=\"utf-8\") as f:\r\n",
    "    test_data=json.load(f)\r\n",
    "print(test_data[0][\"paragraphs\"][0][\"sentences\"][0][\"tokens\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'id': 0, 'orth': 'mảnh', 'tag': 'Nc', 'pos': 'NOUN', 'head': 1, 'dep': 'compound'}, {'id': 1, 'orth': 'đất', 'tag': 'N', 'pos': 'NOUN', 'head': 5, 'dep': 'nsubj'}, {'id': 2, 'orth': 'của', 'tag': 'E', 'pos': 'ADP', 'head': 1, 'dep': 'case'}, {'id': 3, 'orth': 'đạn', 'tag': 'N', 'pos': 'NOUN', 'head': -2, 'dep': 'nmod'}, {'id': 4, 'orth': 'bom', 'tag': 'N', 'pos': 'NOUN', 'head': -1, 'dep': 'compound'}, {'id': 5, 'orth': 'không', 'tag': 'R', 'pos': 'X', 'head': 1, 'dep': 'advmod'}, {'id': 6, 'orth': 'còn', 'tag': 'V', 'pos': 'VERB', 'head': 0, 'dep': 'ROOT'}, {'id': 7, 'orth': 'người', 'tag': 'N', 'pos': 'NOUN', 'head': -1, 'dep': 'obj'}, {'id': 8, 'orth': 'nghèo', 'tag': 'A', 'pos': 'ADJ', 'head': -1, 'dep': 'amod'}, {'id': 9, 'orth': '.', 'tag': '.', 'pos': 'PUNCT', 'head': -3, 'dep': 'punct'}]\n",
      "[{'id': 0, 'orth': 'giờ', 'tag': 'N', 'pos': 'PUNCT', 'head': 3, 'dep': 'nsubj'}, {'id': 1, 'orth': 'G', 'tag': 'Ny', 'pos': 'NOUN', 'head': -1, 'dep': 'compound'}, {'id': 2, 'orth': 'đã', 'tag': 'R', 'pos': 'X', 'head': 1, 'dep': 'advmod'}, {'id': 3, 'orth': 'điểm', 'tag': 'V', 'pos': 'VERB', 'head': 0, 'dep': 'ROOT'}, {'id': 4, 'orth': ',', 'tag': ',', 'pos': 'PUNCT', 'head': -1, 'dep': 'punct'}, {'id': 5, 'orth': 'gậy_gộc', 'tag': 'N', 'pos': 'NOUN', 'head': 6, 'dep': 'nsubj'}, {'id': 6, 'orth': ',', 'tag': ',', 'pos': 'PUNCT', 'head': 1, 'dep': 'punct'}, {'id': 7, 'orth': 'nước', 'tag': 'N', 'pos': 'NOUN', 'head': -2, 'dep': 'conj'}, {'id': 8, 'orth': ',', 'tag': ',', 'pos': 'PUNCT', 'head': 1, 'dep': 'punct'}, {'id': 9, 'orth': 'lửa', 'tag': 'N', 'pos': 'NOUN', 'head': -4, 'dep': 'conj'}, {'id': 10, 'orth': '...', 'tag': '...', 'pos': 'PUNCT', 'head': 1, 'dep': 'punct'}, {'id': 11, 'orth': 'sẵn_sàng', 'tag': 'A', 'pos': 'ADJ', 'head': -8, 'dep': 'xcomp'}, {'id': 12, 'orth': 'để', 'tag': 'E', 'pos': 'ADP', 'head': 1, 'dep': 'case'}, {'id': 13, 'orth': 'tách', 'tag': 'V', 'pos': 'VERB', 'head': -2, 'dep': 'mark'}, {'id': 14, 'orth': 'chúng', 'tag': 'P', 'pos': 'PROPN', 'head': -1, 'dep': 'obj'}, {'id': 15, 'orth': 'nếu', 'tag': 'C', 'pos': 'CCONJ', 'head': 1, 'dep': 'cc'}, {'id': 16, 'orth': 'xảy', 'tag': 'V', 'pos': 'VERB', 'head': -3, 'dep': 'conj'}, {'id': 17, 'orth': 'ra', 'tag': 'R', 'pos': 'X', 'head': -1, 'dep': 'advmod'}, {'id': 18, 'orth': '\"', 'tag': '\"', 'pos': 'PUNCT', 'head': 2, 'dep': 'punct'}, {'id': 19, 'orth': 'song', 'tag': 'M', 'pos': 'NUM', 'head': 1, 'dep': 'nummod'}, {'id': 20, 'orth': 'hổ', 'tag': 'N', 'pos': 'NOUN', 'head': -4, 'dep': 'obj'}, {'id': 21, 'orth': 'đấu', 'tag': 'V', 'pos': 'VERB', 'head': -1, 'dep': 'xcomp'}, {'id': 22, 'orth': '\"', 'tag': '\"', 'pos': 'PUNCT', 'head': -2, 'dep': 'punct'}, {'id': 23, 'orth': '.', 'tag': '.', 'pos': 'PUNCT', 'head': -20, 'dep': 'punct'}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Convert từ list từ qua câu (TRAIN DATASET)\r\n",
    "count=0\r\n",
    "orth=[]\r\n",
    "tag=[]\r\n",
    "pos=[]\r\n",
    "head=[]\r\n",
    "dep=[]\r\n",
    "for i in data:\r\n",
    "    for j in i[\"paragraphs\"][0][\"sentences\"][0][\"tokens\"]:\r\n",
    "        orth.append(j[\"orth\"])\r\n",
    "        tag.append(j[\"tag\"])\r\n",
    "        pos.append(j[\"pos\"])\r\n",
    "        head.append(j[\"head\"])\r\n",
    "        dep.append(j[\"dep\"])\r\n",
    "df=pd.DataFrame({\"orth\":orth,\"tag\":tag,\"pos\":pos,\"head\":head,\"dep\":dep})\r\n",
    "df.loc[df[\"pos\"]==\"NOUN\"].head(30)\r\n",
    "\r\n",
    "token=\"\"\r\n",
    "train_sentences=[]\r\n",
    "train_postokenslist=[]\r\n",
    "train_deptokenslist=[]\r\n",
    "postoken=[]\r\n",
    "deptoken=[]\r\n",
    "datadict={}\r\n",
    "myData=[]\r\n",
    "for i,j,z in zip(orth,pos,dep):\r\n",
    "    if j!=\"PUNCT\":\r\n",
    "        token=token+i+\" \"\r\n",
    "        postoken.append(j)\r\n",
    "        deptoken.append(z)\r\n",
    "    if i==\".\":\r\n",
    "        train_sentences.append(token)\r\n",
    "        train_postokenslist.append(postoken)\r\n",
    "        train_deptokenslist.append(deptoken)\r\n",
    "        deptoken=[]\r\n",
    "        postoken=[]\r\n",
    "        token=\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Convert từ list từ qua câu (TEST DATASET)\r\n",
    "count=0\r\n",
    "orth=[]\r\n",
    "tag=[]\r\n",
    "pos=[]\r\n",
    "head=[]\r\n",
    "dep=[]\r\n",
    "for i in test_data:\r\n",
    "    for j in i[\"paragraphs\"][0][\"sentences\"][0][\"tokens\"]:\r\n",
    "        orth.append(j[\"orth\"])\r\n",
    "        tag.append(j[\"tag\"])\r\n",
    "        pos.append(j[\"pos\"])\r\n",
    "        head.append(j[\"head\"])\r\n",
    "        dep.append(j[\"dep\"])\r\n",
    "test_df=pd.DataFrame({\"orth\":orth,\"tag\":tag,\"pos\":pos,\"head\":head,\"dep\":dep})\r\n",
    "test_df.loc[df[\"pos\"]==\"NOUN\"].head(30)\r\n",
    "\r\n",
    "token=\"\"\r\n",
    "test_sentences=[]\r\n",
    "test_postokenslist=[]\r\n",
    "test_deptokenslist=[]\r\n",
    "postoken=[]\r\n",
    "deptoken=[]\r\n",
    "datadict={}\r\n",
    "myData=[]\r\n",
    "for i,j,z in zip(orth,pos,dep):\r\n",
    "    if j!=\"PUNCT\":\r\n",
    "        token=token+i+\" \"\r\n",
    "        postoken.append(j)\r\n",
    "        deptoken.append(z)\r\n",
    "    if i==\".\":\r\n",
    "        test_sentences.append(token)\r\n",
    "        test_postokenslist.append(postoken)\r\n",
    "        test_deptokenslist.append(deptoken)\r\n",
    "        deptoken=[]\r\n",
    "        postoken=[]\r\n",
    "        token=\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "#Convert hôm nay -> hôm_nay\r\n",
    "t=[]\r\n",
    "for i in df[\"orth\"].tolist():\r\n",
    "    for each in i:\r\n",
    "        if each==\"_\":\r\n",
    "            t.append(i.lower())\r\n",
    "            break\r\n",
    "t"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['chiến_tranh',\n",
       " 'quê_hương',\n",
       " 'thái_mỹ',\n",
       " 'củ_chi',\n",
       " 'gia_đình',\n",
       " 'chính_sách',\n",
       " 'thái_mỹ',\n",
       " 'mất_mát',\n",
       " 'liệt_sĩ',\n",
       " 'bom_đạn',\n",
       " 'gia_đình',\n",
       " 'buôn_lậu',\n",
       " 'thái_mỹ',\n",
       " 'bây_giờ',\n",
       " 'trở_mình',\n",
       " 'đồn_bót',\n",
       " 'cùi_tay',\n",
       " 'lạ_đời',\n",
       " 'xe_máy',\n",
       " 'băng_băng',\n",
       " 'phẳng_lì',\n",
       " 'tất_cả',\n",
       " 'nội_đồng',\n",
       " 'thành_quả',\n",
       " 'nhà_nước',\n",
       " 'nhân_dân',\n",
       " 'tự_hào',\n",
       " 'tình_nguyện',\n",
       " 'thu_hẹp',\n",
       " 'người_người',\n",
       " 'ai_nấy',\n",
       " 'cựu_chiến_binh',\n",
       " 'nhẹ_tênh',\n",
       " 'cuộc_sống',\n",
       " 'thái_mỹ',\n",
       " 'học_sinh',\n",
       " 'xanh_ngắt',\n",
       " 'thấp_thoáng',\n",
       " 'dây_điện',\n",
       " 'gia_đình',\n",
       " 'không_những',\n",
       " 'ban_đêm',\n",
       " 'sáng_choang',\n",
       " 'dự_án',\n",
       " 'thủy_lợi',\n",
       " 'trị_giá',\n",
       " 'ra_đời',\n",
       " 'vô_vàn',\n",
       " 'nhọc_nhằn',\n",
       " 'thi_đua',\n",
       " 'mặt_đất',\n",
       " 'đồn_bót',\n",
       " 'trơ_trơ',\n",
       " 'mồ_hôi',\n",
       " 'bằng_không',\n",
       " 'buôn_lậu',\n",
       " 'đan_lát',\n",
       " 'thoi_thóp',\n",
       " 'bắt_đầu',\n",
       " 'bảo_lãnh',\n",
       " 'vận_động',\n",
       " 'trở_về',\n",
       " 'cải_tạo',\n",
       " 'khai_hoang',\n",
       " 'vận_động',\n",
       " 'hồi_sinh',\n",
       " 'đường_đất',\n",
       " 'vận_động',\n",
       " 'vận_động',\n",
       " 'tháo_gỡ',\n",
       " 'thay_da_đổi_thịt',\n",
       " 'thái_mỹ',\n",
       " 'nhân_dân',\n",
       " 'đảng_viên',\n",
       " 'thành_viên',\n",
       " 'hội_đoàn',\n",
       " 'mạch_máu',\n",
       " 'tế_bào',\n",
       " 'chủ_tịch',\n",
       " 'bùi_văn_luyến',\n",
       " 'coi_bộ',\n",
       " 'quan_trọng',\n",
       " 'hiện_nay',\n",
       " 'nhân_dân',\n",
       " 'phụ_trách',\n",
       " 'gia_đình',\n",
       " 'chủ_trương',\n",
       " 'hưởng_ứng',\n",
       " 'chịu_thua',\n",
       " 'trước_nhất',\n",
       " 'đảng_viên',\n",
       " 'làm_gương',\n",
       " 'xuất_khẩu',\n",
       " 'lao_động',\n",
       " 'du_học_sinh',\n",
       " 'nước_ngoài',\n",
       " 'mở_mang',\n",
       " 'kiến_thức',\n",
       " 'lao_động',\n",
       " 'làm_việc',\n",
       " 'nước_ngoài',\n",
       " 'gia_đình',\n",
       " 'tiếp_cận',\n",
       " 'môi_trường',\n",
       " 'làm_việc',\n",
       " 'công_nghiệp',\n",
       " 'làm_việc',\n",
       " 'nước_ngoài',\n",
       " 'trở_về',\n",
       " 'hầu_hết',\n",
       " 'tiếp_tục',\n",
       " 'làm_việc',\n",
       " 'nghèo_khó',\n",
       " 'cơ_sở',\n",
       " 'trang_trại',\n",
       " 'công_ăn_việc_làm',\n",
       " 'lao_động',\n",
       " 'trở_về',\n",
       " 'quyết_tâm',\n",
       " 'dành_dụm',\n",
       " 'tiếp_tục',\n",
       " 'văn_hóa',\n",
       " 'đại_học',\n",
       " 'trở_về',\n",
       " 'quyết_tâm',\n",
       " 'dành_dụm',\n",
       " 'tiếp_tục',\n",
       " 'văn_hóa',\n",
       " 'đại_học',\n",
       " 'công_bố',\n",
       " 'phổ_cập',\n",
       " 'giáo_dục',\n",
       " 'dự_kiến',\n",
       " 'hoàn_thành',\n",
       " 'phổ_cập',\n",
       " 'thần_kỳ',\n",
       " 'quê_hương',\n",
       " 'cay_cực',\n",
       " 'vinh_dự',\n",
       " 'danh_hiệu',\n",
       " 'tập_thể',\n",
       " 'anh_hùng',\n",
       " 'lao_động',\n",
       " 'thời_kỳ',\n",
       " 'đổi_mới',\n",
       " 'đổi_mới',\n",
       " 'nông_dân',\n",
       " 'chân_chất',\n",
       " 'cần_cù',\n",
       " 'giàu_có',\n",
       " 'tập_thể',\n",
       " 'vững_mạnh',\n",
       " 'đầu_tàu',\n",
       " 'cán_bộ',\n",
       " 'tập_huấn',\n",
       " 'tập_huấn',\n",
       " 'chăn_nuôi',\n",
       " 'truyền_thống',\n",
       " 'điều_kiện',\n",
       " 'lao_động',\n",
       " 'nước_ngoài',\n",
       " 'cầu_nối',\n",
       " 'liệt_sĩ',\n",
       " 'gia_đình',\n",
       " 'chính_sách',\n",
       " 'thương_binh',\n",
       " 'con_số',\n",
       " 'nước_mắt',\n",
       " 'vùng_đất',\n",
       " 'ngặt_nghèo',\n",
       " 'đau_thương',\n",
       " 'quê_hương',\n",
       " 'bất_ngờ',\n",
       " 'sức_sống',\n",
       " 'mãnh_liệt',\n",
       " 'trở_về',\n",
       " 'đời_thường',\n",
       " 'cựu_chiến_binh',\n",
       " 'phan_văn_đu',\n",
       " 'phạm_văn_thanh',\n",
       " 'lão_nông',\n",
       " 'cánh_tay',\n",
       " 'nguyên_vẹn',\n",
       " 'gia_đình',\n",
       " 'gương_mẫu',\n",
       " 'câu_chuyện',\n",
       " 'lời_lãi',\n",
       " 'vui_mừng',\n",
       " 'thông_báo',\n",
       " 'thương_binh',\n",
       " 'quá_khứ',\n",
       " 'vết_thương',\n",
       " 'tóm_tắt',\n",
       " 'tổng_tấn_công',\n",
       " 'y_nguyên',\n",
       " 'chiến_tranh',\n",
       " 'tháo_gỡ',\n",
       " 'tháo_gỡ',\n",
       " 'cánh_tay',\n",
       " 'thân_thể',\n",
       " 'trụ_sở',\n",
       " 'nhà_văn_hóa',\n",
       " 'trị_giá',\n",
       " 'mua_đi_bán_lại',\n",
       " 'ăn_học',\n",
       " 'cô_giáo',\n",
       " 'cô_giáo',\n",
       " 'thái_mỹ',\n",
       " 'hình_ảnh',\n",
       " 'chủ_tịch',\n",
       " 'cựu_chiến_binh',\n",
       " 'tổ_trưởng',\n",
       " 'nhân_dân',\n",
       " 'xe_máy',\n",
       " 'cùi_tay',\n",
       " 'ốm_đau',\n",
       " 'bệnh_hoạn',\n",
       " 'có_mặt',\n",
       " 'đồng_bào',\n",
       " 'lũ_lụt',\n",
       " 'hỏa_hoạn',\n",
       " 'thương_binh',\n",
       " 'lặn_lội',\n",
       " 'vận_động',\n",
       " 'làm_việc',\n",
       " 'tất_cả',\n",
       " 'cùi_tay',\n",
       " 'vậy_mà',\n",
       " 'gia_đình',\n",
       " 'xóa_đói_giảm_nghèo',\n",
       " 'chăn_nuôi',\n",
       " 'gầy_dựng',\n",
       " 'vững_chãi',\n",
       " 'máu_xương',\n",
       " 'mồ_hôi',\n",
       " 'con_người',\n",
       " 'lạ_kỳ',\n",
       " 'anh_hùng',\n",
       " 'công_an',\n",
       " 'dương_văn_nam',\n",
       " 'vận_động',\n",
       " 'việc_làm',\n",
       " 'đối_tượng',\n",
       " 'trộm_cắp',\n",
       " 'chắt_chiu',\n",
       " 'xây_dựng',\n",
       " 'nhà_tình_nghĩa',\n",
       " 'tình_thương',\n",
       " 'tổ_chức',\n",
       " 'hội_an',\n",
       " 'số_phận',\n",
       " 'sự_thật',\n",
       " 'lận_đận',\n",
       " 'số_phận',\n",
       " 'vợ_chồng',\n",
       " 'công_nhân',\n",
       " 'tố_cáo',\n",
       " 'tiêu_cực',\n",
       " 'ngày_xưa',\n",
       " 'bây_giờ',\n",
       " 'phiêu_bạt',\n",
       " 'khắp_nơi',\n",
       " 'gia_đình',\n",
       " 'dắt_díu',\n",
       " 'bây_giờ',\n",
       " 'vợ_chồng',\n",
       " 'công_nhân',\n",
       " 'bám_trụ',\n",
       " 'sài_gòn',\n",
       " 'ngờ_vực',\n",
       " 'bạn_bè',\n",
       " 'quyết_định',\n",
       " 'pháp_luật',\n",
       " 'danh_dự',\n",
       " 'khẳng_định',\n",
       " 'tiền_bạc',\n",
       " 'đối_với',\n",
       " 'tất_cả',\n",
       " 'gia_đình',\n",
       " 'túng_quẫn',\n",
       " 've_chai',\n",
       " 'tiêu_cực',\n",
       " 'đeo_đuổi',\n",
       " 'của_cải',\n",
       " 'lần_lượt',\n",
       " 'đội_nón_ra_đi',\n",
       " 'chúng_tôi',\n",
       " 'vợ_chồng',\n",
       " 'em_gái',\n",
       " 'con_người',\n",
       " 'chen_chúc',\n",
       " 've_chai',\n",
       " 'đạm_bạc',\n",
       " 'quày_quả',\n",
       " 'xe_đạp',\n",
       " 'cọc_cạch',\n",
       " 'vợ_chồng',\n",
       " 'tạm_bợ',\n",
       " 'gia_đình',\n",
       " 'công_nhân',\n",
       " 'tiêu_cực',\n",
       " 'tá_túc',\n",
       " 'chúng_tôi',\n",
       " 'chạnh_lòng',\n",
       " 'bây_giờ',\n",
       " 'túng_quẫn',\n",
       " 'bần_hàn',\n",
       " 'vậy_sao',\n",
       " 'công_ty',\n",
       " 'giải_trình',\n",
       " 'tây_nguyên',\n",
       " 'nam_bộ',\n",
       " 'khả_năng',\n",
       " 'hà_nội',\n",
       " 'trường_học',\n",
       " 'phát_hiện',\n",
       " 'học_sinh',\n",
       " 'giáo_viên',\n",
       " 'ma_túy',\n",
       " 'tiếp_tục',\n",
       " 'gia_tăng',\n",
       " 'phát_hiện',\n",
       " 'lập_tức',\n",
       " 'mặt_hàng',\n",
       " 'biên_bản',\n",
       " 'thu_giữ',\n",
       " 'nguyễn_thế_khanh',\n",
       " 'chi_cục',\n",
       " 'mặt_hàng',\n",
       " 'điện_tử',\n",
       " 'qui_định',\n",
       " 'nhập_khẩu',\n",
       " 'hình_thức',\n",
       " 'lao_động',\n",
       " 'việc_làm',\n",
       " 'hợp_đồng',\n",
       " 'lao_động',\n",
       " 'thực_hiện',\n",
       " 'thời_hạn',\n",
       " 'công_việc',\n",
       " 'công_nhân',\n",
       " 'xây_dựng',\n",
       " 'giới_thiệu',\n",
       " 'mô_hình',\n",
       " 'xóa_đói_giảm_nghèo',\n",
       " 'phát_triển',\n",
       " 'trường_hợp',\n",
       " 'nghiên_cứu',\n",
       " 'tựa_đề',\n",
       " 'tác_động',\n",
       " 'phát_triển',\n",
       " 'cơ_sở_hạ_tầng',\n",
       " 'đối_với',\n",
       " 'nông_thôn',\n",
       " 'trường_hợp',\n",
       " 'nghiên_cứu',\n",
       " 'trình_bày',\n",
       " 'thảo_luận',\n",
       " 'thông_qua',\n",
       " 'hội_nghị',\n",
       " 'truyền_hình',\n",
       " 'tham_gia',\n",
       " 'quốc_gia',\n",
       " 'đối_thoại',\n",
       " 'trực_tuyến',\n",
       " 'phú_yên',\n",
       " 'cán_bộ',\n",
       " 'lập_tức',\n",
       " 'thông_báo',\n",
       " 'người_thân',\n",
       " 'bạn_bè',\n",
       " 'xây_dựng',\n",
       " 'dự_án',\n",
       " 'qui_hoạch',\n",
       " 'phát_triển',\n",
       " 'dân_cư',\n",
       " 'xuân_hải',\n",
       " 'đầu_tư',\n",
       " 'phương_thức',\n",
       " 'chuyển_giao',\n",
       " 'sử_dụng',\n",
       " 'xây_dựng',\n",
       " 'thực_chất',\n",
       " 'hạ_tầng',\n",
       " 'dự_án',\n",
       " 'phú_yên',\n",
       " 'phê_duyệt',\n",
       " 'sông_cầu',\n",
       " 'thực_hiện',\n",
       " 'sơ_đồ',\n",
       " 'qui_hoạch',\n",
       " 'chính_quyền',\n",
       " 'sở_tại',\n",
       " 'công_bố',\n",
       " 'công_khai',\n",
       " 'công_khai',\n",
       " 'trụ_sở',\n",
       " 'xuân_hải',\n",
       " 'sổ_đỏ',\n",
       " 'vì_sao',\n",
       " 'chúng_tôi',\n",
       " 'tiếp_tục',\n",
       " 'điều_tra',\n",
       " 'động_cơ',\n",
       " 'cán_bộ',\n",
       " 'địa_phương',\n",
       " 'chúng_tôi',\n",
       " 'đấu_tranh',\n",
       " 'tiêu_cực',\n",
       " 'bộ_máy',\n",
       " 'nhà_nước',\n",
       " 'chúng_tôi',\n",
       " 'tuân_thủ',\n",
       " 'pháp_luật',\n",
       " 'chính_quyền',\n",
       " 'sai_phạm',\n",
       " 'thủ_tục',\n",
       " 'quản_lý',\n",
       " 'gánh_chịu',\n",
       " 'hậu_quả',\n",
       " 'chính_quyền',\n",
       " 'chính_quyền',\n",
       " 'chấp_nhận',\n",
       " 'ngân_hàng',\n",
       " 'chắc_chắn',\n",
       " 'hơn_nữa',\n",
       " 'giá_cả',\n",
       " 'ủy_ban',\n",
       " 'có_thể',\n",
       " 'hợp_đồng',\n",
       " 'vô_hiệu',\n",
       " 'công_trình',\n",
       " 'thi_công',\n",
       " 'bê_bối',\n",
       " 'lắp_đặt',\n",
       " 'sử_dụng',\n",
       " 'ngoài_ra',\n",
       " 'đáng_lẽ',\n",
       " 'đường_ống',\n",
       " 'tiêu_chuẩn',\n",
       " 'xây_dựng',\n",
       " 'hệ_thống',\n",
       " 'đơn_vị',\n",
       " 'thi_công',\n",
       " 'công_trình',\n",
       " 'công_trình',\n",
       " 'ủng_hộ',\n",
       " 'bệnh_nhân',\n",
       " 'trương_xuân_đại',\n",
       " 'bạn_đọc',\n",
       " 'bày_tỏ',\n",
       " 'chia_sẻ',\n",
       " 'ủng_hộ',\n",
       " 'biên_tập',\n",
       " 'tuổi_trẻ',\n",
       " 'quyết_định',\n",
       " 'công_nhân',\n",
       " 'tố_cáo',\n",
       " 'tiêu_cực',\n",
       " 'liên_cảng_a5',\n",
       " 'đặt_cược',\n",
       " 'hiệp_sĩ',\n",
       " 'ra_sao',\n",
       " 'đáng_lẽ',\n",
       " 'tôn_vinh',\n",
       " 'trái_lại',\n",
       " 'con_người',\n",
       " 'cuộc_sống',\n",
       " 'lại_nữa',\n",
       " 'thanh_tra',\n",
       " 'xác_định',\n",
       " 'sai_phạm',\n",
       " 'xử_lý',\n",
       " 'câu_chuyện',\n",
       " 'đàng_hoàng',\n",
       " 'công_nhân',\n",
       " 'dũng_cảm',\n",
       " 'vậy_mà',\n",
       " 'hầu_như',\n",
       " 'lang_bạt',\n",
       " 'vì_sao',\n",
       " 'hôm_nay',\n",
       " 'chúng_ta',\n",
       " 'lầm_than',\n",
       " 'hôm_nay',\n",
       " 'công_nhân',\n",
       " 'bảo_vệ',\n",
       " 'minh_chứng',\n",
       " 'kết_quả',\n",
       " 'nhãn_tiền',\n",
       " 'câu_chuyện',\n",
       " 'đàng_hoàng',\n",
       " 'con_người',\n",
       " 'xã_hội',\n",
       " 'chính_thức',\n",
       " 'kết_luận',\n",
       " 'hoan_nghênh',\n",
       " 'biểu_dương',\n",
       " 'việc_làm',\n",
       " 'tuy_nhiên',\n",
       " 'chính_quyền',\n",
       " 'không_thể',\n",
       " 'tại_sao',\n",
       " 'mong_mỏi',\n",
       " 'công_bằng',\n",
       " 'thực_hiện',\n",
       " 'có_thể',\n",
       " 'đầu_tàu',\n",
       " 'rộng_rãi',\n",
       " 'độc_giả',\n",
       " 'nhất_là',\n",
       " 'doanh_nghiệp',\n",
       " 'có_thể',\n",
       " 'lên_tiếng',\n",
       " 'biện_pháp',\n",
       " 'trợ_giúp',\n",
       " 'một_vài',\n",
       " 'biện_pháp',\n",
       " 'hành_chính',\n",
       " 'xuất_phát',\n",
       " 'trễ_tràng',\n",
       " 'tiêu_cực',\n",
       " 'tố_cáo',\n",
       " 'công_nhân',\n",
       " 'dũng_cảm',\n",
       " 'tố_cáo',\n",
       " 'tiêu_cực',\n",
       " 'sáng_tỏ',\n",
       " 'pháp_luật',\n",
       " 'bảo_vệ',\n",
       " 'sẵn_sàng',\n",
       " 'công_nhân',\n",
       " 'tố_cáo',\n",
       " 'tiêu_cực',\n",
       " 'liên_cảng_a5',\n",
       " 'công_ty',\n",
       " 'làm_việc',\n",
       " 'đề_nghị',\n",
       " 'liên_hệ',\n",
       " 'chúng_tôi',\n",
       " 'công_ty',\n",
       " 'xây_lắp',\n",
       " 'vật_tư',\n",
       " 'xây_dựng',\n",
       " 'nguyễn_công_trứ',\n",
       " 'tp_hcm',\n",
       " 'trần_nhất_thiện',\n",
       " 'giám_đốc',\n",
       " 'công_ty',\n",
       " 'triều_phú',\n",
       " 'công_ty',\n",
       " 'chúng_tôi',\n",
       " 'có_thể',\n",
       " 'vợ_chồng',\n",
       " 'làm_việc',\n",
       " 'theo_dõi',\n",
       " 'câu_chuyện',\n",
       " 'thẳng_thắn',\n",
       " 'xứng_đáng',\n",
       " 'chỗ_đứng',\n",
       " 'xã_hội',\n",
       " 'pháp_luật',\n",
       " 'bảo_vệ',\n",
       " 'hoàn_cảnh',\n",
       " 'khó_khăn',\n",
       " 'vợ_chồng',\n",
       " 'trang_trại',\n",
       " 'chúng_tôi',\n",
       " 'công_nhân',\n",
       " 'trương_xuân_đại',\n",
       " 'pháp_luật',\n",
       " 'luật_sư',\n",
       " 'bảo_vệ',\n",
       " 'quyền_lợi',\n",
       " 'pháp_luật',\n",
       " 'đề_nghị',\n",
       " 'hòa_giải',\n",
       " 'số_phận',\n",
       " 'sự_thật',\n",
       " 'chủ_tịch',\n",
       " 'lê_thanh_hải',\n",
       " 'an_toàn',\n",
       " 'giao_thông',\n",
       " 'vấn_đề',\n",
       " 'bức_xúc',\n",
       " 'vi_phạm',\n",
       " 'lực_lượng',\n",
       " 'công_an',\n",
       " 'mất_sức',\n",
       " 'xử_phạt',\n",
       " 'vi_phạm',\n",
       " 'giao_thông',\n",
       " 'tình_trạng',\n",
       " 'lơi_lỏng',\n",
       " 'chủ_quan',\n",
       " 'xử_phạt',\n",
       " 'sea_games_22',\n",
       " 'đối_với',\n",
       " 'đơn_vị',\n",
       " 'kinh_doanh',\n",
       " 'lấn_chiếm',\n",
       " 'lề_đường',\n",
       " 'vi_phạm',\n",
       " 'cương_quyết',\n",
       " 'giấy_phép',\n",
       " 'kinh_doanh',\n",
       " 'liên_quan',\n",
       " 'kinh_doanh',\n",
       " 'địa_điểm',\n",
       " 'điều_kiện',\n",
       " 'bắt_buộc',\n",
       " 'sự_thật',\n",
       " 'kiểm_lâm',\n",
       " 'mâu_thuẫn',\n",
       " 'cãi_vã',\n",
       " 'một_số',\n",
       " 'công_nhân',\n",
       " 'làm_việc',\n",
       " 'thủy_điện',\n",
       " 'ia_me',\n",
       " 'tự_ái',\n",
       " 'cãi_vã',\n",
       " 'trọng_thương',\n",
       " 'trình_diện',\n",
       " 'cơ_quan',\n",
       " 'công_an',\n",
       " 'vụ_việc',\n",
       " 'cơ_quan',\n",
       " 'chức_năng',\n",
       " 'tiếp_tục',\n",
       " 'điều_tra',\n",
       " 'góp_ý',\n",
       " 'dự_thảo',\n",
       " 'nghị_định',\n",
       " 'hướng_dẫn',\n",
       " 'thi_hành',\n",
       " 'đất_đai',\n",
       " 'hạn_chế',\n",
       " 'thái_độ',\n",
       " 'vô_cảm',\n",
       " 'đầu_tiên',\n",
       " 'nghị_định',\n",
       " 'hành_vi',\n",
       " 'vi_phạm',\n",
       " 'hình_thức',\n",
       " 'xử_lý',\n",
       " 'kỷ_luật',\n",
       " 'đối_với',\n",
       " 'quản_lý',\n",
       " 'qui_định',\n",
       " 'chi_tiết',\n",
       " 'rõ_ràng',\n",
       " 'góp_phần',\n",
       " 'hạn_chế',\n",
       " 'thái_độ',\n",
       " 'thủ_tướng',\n",
       " 'phan_văn_khải',\n",
       " 'vô_cảm',\n",
       " 'cán_bộ',\n",
       " 'quản_lý',\n",
       " 'nhà_nước',\n",
       " 'bộ_trưởng',\n",
       " 'tài_nguyên',\n",
       " 'môi_trường',\n",
       " 'mai_ái_trực',\n",
       " 'nhấn_mạnh',\n",
       " 'hội_nghị',\n",
       " 'góp_ý',\n",
       " 'dự_thảo',\n",
       " 'nghị_định',\n",
       " 'hướng_dẫn',\n",
       " 'thi_hành',\n",
       " 'đất_đai',\n",
       " 'hôm_qua',\n",
       " 'quá_trời',\n",
       " 'thủ_tục',\n",
       " 'bao_nhiêu',\n",
       " 'thủ_tục',\n",
       " 'bao_nhiêu',\n",
       " 'văn_phòng',\n",
       " 'đăng_ký',\n",
       " 'sử_dụng',\n",
       " 'văn_phòng',\n",
       " 'đăng_ký',\n",
       " 'sử_dụng',\n",
       " 'bộ_phận',\n",
       " 'hành_chính',\n",
       " 'tổ_chức',\n",
       " 'sự_nghiệp',\n",
       " 'hoạt_động',\n",
       " 'dịch_vụ',\n",
       " 'nhân_lực',\n",
       " 'biên_chế',\n",
       " 'thứ_trưởng',\n",
       " 'trấn_an',\n",
       " 'thỏa_thuận',\n",
       " 'thỏa_thuận',\n",
       " 'hội_nghị',\n",
       " 'hôm_qua',\n",
       " 'tiếng_nói',\n",
       " 'tài_nguyên',\n",
       " 'môi_trường',\n",
       " 'đồng_thanh',\n",
       " 'loại_bỏ',\n",
       " 'điều_khoản',\n",
       " 'dự_thảo',\n",
       " 'doanh_nghiệp',\n",
       " 'nói_chuyện',\n",
       " 'cơ_quan',\n",
       " 'quản_lý',\n",
       " 'nhà_nước',\n",
       " 'suy_nghĩ',\n",
       " 'đồng_chí',\n",
       " 'qui_định',\n",
       " 'bộ_trưởng',\n",
       " 'mai_ái_trực',\n",
       " 'tiếp_lời',\n",
       " 'áp_dụng',\n",
       " 'cơ_chế',\n",
       " 'thỏa_thuận',\n",
       " 'thu_hồi',\n",
       " 'trường_hợp',\n",
       " 'qui_định',\n",
       " 'doanh_nghiệp',\n",
       " 'thực_hiện',\n",
       " 'cơ_chế',\n",
       " 'quyền_lực',\n",
       " 'hành_chính',\n",
       " 'nhà_nước',\n",
       " 'mô_hình',\n",
       " 'cho_phép',\n",
       " 'trường_hợp',\n",
       " 'phạm_luật',\n",
       " 'hiện_nay',\n",
       " 'lã_thị_kim_oanh',\n",
       " 'khẳng_định',\n",
       " 'bảo_lãnh',\n",
       " 'hội_đồng',\n",
       " 'xét_xử',\n",
       " 'phúc_thẩm',\n",
       " 'lã_thị_kim_oanh',\n",
       " 'bắt_đầu',\n",
       " 'thẩm_vấn',\n",
       " 'ngân_hàng',\n",
       " 'đối_với',\n",
       " 'tiếp_thị',\n",
       " 'bị_cáo',\n",
       " 'lã_thị_kim_oanh',\n",
       " 'khẳng_định',\n",
       " 'dự_án',\n",
       " 'đầu_tư',\n",
       " 'kinh_doanh',\n",
       " 'cụ_thể',\n",
       " 'công_trình',\n",
       " 'trung_tâm',\n",
       " 'tiếp_thị',\n",
       " 'hàng_bồ',\n",
       " 'tất_cả',\n",
       " 'ban_ngành',\n",
       " 'lã_thị_kim_oanh',\n",
       " 'thủ_tục',\n",
       " 'triển_khai',\n",
       " 'công_trình',\n",
       " 'phức_tạp',\n",
       " 'bị_cáo',\n",
       " 'trả_lời',\n",
       " 'thế_nào',\n",
       " 'dự_kiến',\n",
       " 'hôm_nay',\n",
       " 'thẩm_vấn',\n",
       " 'nội_dung',\n",
       " 'cố_ý',\n",
       " 'hậu_quả',\n",
       " 'nghiêm_trọng',\n",
       " 'bị_cáo',\n",
       " 'triển_khai',\n",
       " 'dự_án',\n",
       " 'hoàn_trả',\n",
       " 'công_ty',\n",
       " 'ủy_quyền',\n",
       " 'hợp_đồng',\n",
       " 'tín_dụng',\n",
       " 'hộ_chiếu',\n",
       " 'dịch_vụ',\n",
       " 'dịch_vụ',\n",
       " 'đối_với',\n",
       " 'chúng_tôi',\n",
       " 'có_thể',\n",
       " 'thất_thu',\n",
       " 'khăn_gói',\n",
       " 'cửa_quan',\n",
       " 'thứ_hai',\n",
       " 'chúng_tôi',\n",
       " 'xe_hàng',\n",
       " 'sứ_quán',\n",
       " 'chúng_tôi',\n",
       " 'cửa_sổ',\n",
       " 'phòng_thường_trực',\n",
       " 'xuất_hiện',\n",
       " 'chúng_tôi',\n",
       " 'bảo_vệ',\n",
       " 'chuyên_nghiệp',\n",
       " 'trình_bày',\n",
       " 'lý_do',\n",
       " 'xuất_trình',\n",
       " 'giấy_tờ',\n",
       " 'chứng_minh',\n",
       " 'anh_em',\n",
       " 'sứ_quán',\n",
       " 'hộ_chiếu',\n",
       " 'chúng_tôi',\n",
       " 'tò_vò',\n",
       " 'thường_trực',\n",
       " 'hộ_chiếu',\n",
       " 'giấy_thông_hành',\n",
       " 'khai_sinh',\n",
       " 'qua_lại',\n",
       " 'anh_em',\n",
       " 'lãnh_sự',\n",
       " 'anh_em',\n",
       " 'thông_báo',\n",
       " 'quả_thật',\n",
       " 'lệ_phí',\n",
       " 'thông_thường',\n",
       " 'qui_định',\n",
       " 'chúng_tôi',\n",
       " 'hộ_chiếu',\n",
       " 'lệ_phí',\n",
       " 'hộ_chiếu',\n",
       " 'bình_thường',\n",
       " 'cán_bộ',\n",
       " 'thông_báo',\n",
       " 'cảnh_tượng',\n",
       " 'hỗn_loạn',\n",
       " 'chen_lấn',\n",
       " 'trả_lời',\n",
       " 'qui_định',\n",
       " 'thông_báo',\n",
       " 'cán_bộ',\n",
       " 'hồ_sơ',\n",
       " 'anh_em',\n",
       " 'chị_ta',\n",
       " 'đon_đả',\n",
       " 'hộ_chiếu',\n",
       " 'điện_thoại',\n",
       " 'mồ_hôi_nước_mắt',\n",
       " 'thâm_tâm',\n",
       " 'xót_xa',\n",
       " 'đồng_hồ',\n",
       " 'chúng_tôi',\n",
       " 'hộ_chiếu',\n",
       " 'cộng_hòa',\n",
       " 'xã_hội',\n",
       " 'chủ_nghĩa',\n",
       " 'mới_tinh',\n",
       " 'quốc_huy',\n",
       " 'đỏ_chót',\n",
       " 'anh_chị_em',\n",
       " 'vui_mừng',\n",
       " 'có_lẽ',\n",
       " 'chính_sách',\n",
       " 'chìm_xuồng',\n",
       " 'pháp_luật',\n",
       " 'khách_quan',\n",
       " 'vô_tư',\n",
       " 'vấn_đề',\n",
       " 'vụ_việc',\n",
       " 'chìm_xuồng',\n",
       " 'vì_sao',\n",
       " 'kết_quả',\n",
       " 'chỉ_đạo',\n",
       " 'báo_cáo',\n",
       " 'xử_lý',\n",
       " 'tiêu_cực',\n",
       " 'công_trình',\n",
       " 'số_liệu',\n",
       " 'công_an',\n",
       " 'văn_bản',\n",
       " 'đề_nghị',\n",
       " 'thành_lập',\n",
       " 'hội_đồng',\n",
       " 'giám_định',\n",
       " 'xây_dựng',\n",
       " 'công_trình',\n",
       " 'do_vậy',\n",
       " 'cơ_quan',\n",
       " 'điều_tra',\n",
       " 'yêu_cầu',\n",
       " 'giám_định',\n",
       " 'kết_quả',\n",
       " 'cơ_quan',\n",
       " 'điều_tra',\n",
       " 'vụ_việc',\n",
       " 'chìm_xuồng',\n",
       " 'dư_luận',\n",
       " 'nghi_vấn',\n",
       " 'chắc_chắn',\n",
       " 'tận_cùng',\n",
       " 'mong_muốn',\n",
       " 'vì_sao',\n",
       " 'phúc_thẩm',\n",
       " 'vụ_án',\n",
       " 'lã_thị_kim_oanh',\n",
       " 'bộ_trưởng',\n",
       " 'nhân_chứng',\n",
       " 'tháp_tùng',\n",
       " 'bộ_trưởng',\n",
       " 'một_số',\n",
       " 'cán_bộ',\n",
       " 'nhân_chứng',\n",
       " 'vụ_án',\n",
       " 'nhân_chứng',\n",
       " 'đặc_biệt',\n",
       " 'vội_vã',\n",
       " 'cầu_thang',\n",
       " 'ống_kính',\n",
       " 'máy_ảnh',\n",
       " 'phóng_viên',\n",
       " 'hội_đồng',\n",
       " 'thẩm_định',\n",
       " 'nhận_thức',\n",
       " 'thế_nào',\n",
       " 'công_văn',\n",
       " 'chính_phủ',\n",
       " 'đại_diện',\n",
       " 'viện_kiểm_sát',\n",
       " 'câu_hỏi',\n",
       " 'nhân_chứng',\n",
       " 'bộ_trưởng',\n",
       " 'lê_huy_ngọ',\n",
       " 'quyết_định',\n",
       " 'thẩm_quyền',\n",
       " 'chủ_trương',\n",
       " 'tháo_gỡ',\n",
       " 'khó_khăn',\n",
       " 'công_trình',\n",
       " 'công_văn',\n",
       " 'đồng_ý',\n",
       " 'đề_nghị',\n",
       " 'cho_phép',\n",
       " 'công_ty',\n",
       " 'tiếp_thị',\n",
       " 'tín_dụng',\n",
       " 'kế_hoạch',\n",
       " 'nhà_nước',\n",
       " 'tín_dụng',\n",
       " 'đại_diện',\n",
       " 'viện_kiểm_sát',\n",
       " 'tín_dụng',\n",
       " 'ưu_đãi',\n",
       " 'kế_hoạch',\n",
       " 'chính_phủ',\n",
       " 'bộ_trưởng',\n",
       " 'trả_lời',\n",
       " 'viện_kiểm_sát',\n",
       " 'chủ_trương',\n",
       " 'thứ_trưởng',\n",
       " 'xác_nhận',\n",
       " 'công_văn',\n",
       " 'công_ty',\n",
       " 'tiếp_thị',\n",
       " 'lúng_túng',\n",
       " 'đề_nghị',\n",
       " 'thẩm_định',\n",
       " 'hội_đồng',\n",
       " 'chuyên_môn',\n",
       " 'cơ_quan',\n",
       " 'trách_nhiệm',\n",
       " 'ngân_hàng',\n",
       " 'bị_cáo',\n",
       " 'nguyễn_thiện_luân',\n",
       " 'thứ_trưởng',\n",
       " 'cần_thiết',\n",
       " 'đối_chất',\n",
       " 'thiếu_sót',\n",
       " 'thiếu_sót',\n",
       " 'hành_chính',\n",
       " 'công_ty',\n",
       " 'tiếp_thị',\n",
       " 'ưu_đãi',\n",
       " 'giai_đoạn',\n",
       " 'bị_cáo',\n",
       " 'nguyễn_thiện_luân',\n",
       " 'trình_bày',\n",
       " 'xuất_xứ',\n",
       " 'bút_tích',\n",
       " 'công_văn',\n",
       " 'lã_thị_kim_oanh',\n",
       " 'xác_nhận',\n",
       " 'vụ_trưởng',\n",
       " 'tài_chính',\n",
       " 'kế_toán',\n",
       " 'phan_văn_quán',\n",
       " 'xác_nhận',\n",
       " 'thắc_mắc',\n",
       " 'bị_cáo',\n",
       " 'xác_nhận',\n",
       " 'chủ_trương',\n",
       " 'thể_hiện',\n",
       " 'công_văn',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "for i in t:\r\n",
    "    if bi_gram_list.count(i)==0:\r\n",
    "        bi_gram_list.append(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "rsen=[]\r\n",
    "for i in train_sentences:\r\n",
    "    rsen.append(i[:-1])\r\n",
    "\r\n",
    "test_rsen=[]\r\n",
    "for i in test_sentences:\r\n",
    "    test_rsen.append(i[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "posdata={}\r\n",
    "posdata[\"messages\"]=rsen\r\n",
    "posdata[\"pos\"]=train_postokenslist\r\n",
    "# with open(\"E:/MLCourse/TF2/Notebook/tutorialNotebook/NewTagger/posdata.json\",\"w\",encoding=\"utf-8\") as f:\r\n",
    "#     json.dump(posdata,f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "VNTokenizer=tf.keras.preprocessing.text.Tokenizer(20000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n',oov_token=\"<UNK>\",lower=True)\r\n",
    "VNTokenizer.fit_on_texts(train_sentences)\r\n",
    "seqTokenized=VNTokenizer.texts_to_sequences(train_sentences)\r\n",
    "final_seq=tf.keras.preprocessing.sequence.pad_sequences(seqTokenized)\r\n",
    "maxseqlen=final_seq.shape[1]\r\n",
    "test_seqTokenized=VNTokenizer.texts_to_sequences(test_sentences)\r\n",
    "final_test_seq=tf.keras.preprocessing.sequence.pad_sequences(test_seqTokenized,maxseqlen)\r\n",
    "\r\n",
    "\r\n",
    "depTokenizer=tf.keras.preprocessing.text.Tokenizer(20000)\r\n",
    "depTokenizer.fit_on_texts(train_deptokenslist)\r\n",
    "depTokenized=depTokenizer.texts_to_sequences(train_deptokenslist)\r\n",
    "final_dep=tf.keras.preprocessing.sequence.pad_sequences(depTokenized)\r\n",
    "\r\n",
    "posTokenizer=tf.keras.preprocessing.text.Tokenizer(20000)\r\n",
    "posTokenizer.fit_on_texts(train_postokenslist)\r\n",
    "posTokenized=posTokenizer.texts_to_sequences(train_postokenslist)\r\n",
    "test_pos_Tokenized=posTokenizer.texts_to_sequences(test_postokenslist)\r\n",
    "final_pos=tf.keras.preprocessing.sequence.pad_sequences(posTokenized)\r\n",
    "final_test_pos=tf.keras.preprocessing.sequence.pad_sequences(test_pos_Tokenized,maxlen=final_pos.shape[1])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "final_seq.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1969, 71)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "class FTokenizer():\r\n",
    "    def __init__(self,bi_gram_list):\r\n",
    "        self.bi_gram_list=bi_gram_list\r\n",
    "\r\n",
    "    def bi_gram_checker(self,bi_gram_word):\r\n",
    "        for i in self.bi_gram_list:\r\n",
    "            if (bi_gram_word==i):\r\n",
    "                return True\r\n",
    "        return False\r\n",
    "    \r\n",
    "    def fit_on_text(self,data):\r\n",
    "        word_to_index={}\r\n",
    "        index_to_word={}\r\n",
    "        word_to_index[\"<PAD>\"]=0\r\n",
    "        word_to_index[\"<OOV>\"]=1\r\n",
    "        index_to_word[0]=\"<PAD>\"\r\n",
    "        index_to_word[1]=\"<OOV>\"\r\n",
    "        myContinue=False\r\n",
    "        tokens=[]\r\n",
    "        for eachseq in data:\r\n",
    "            listtokens=eachseq.lower().split(\" \")\r\n",
    "            listtokens.append(\"\")\r\n",
    "            for i in range(0,len(listtokens)-1):\r\n",
    "                if (myContinue):\r\n",
    "                    myContinue=False\r\n",
    "                    continue\r\n",
    "                if (listtokens[i+1]!=\"\"):\r\n",
    "                    pairtext=listtokens[i]+\"_\"+listtokens[i+1]\r\n",
    "                    if (self.bi_gram_checker(pairtext)):\r\n",
    "                        myContinue=True\r\n",
    "                        if (tokens.count(pairtext)==0):\r\n",
    "                            tokens.append(pairtext)\r\n",
    "                if (myContinue==False):  \r\n",
    "                    if (tokens.count(listtokens[i])==0):\r\n",
    "                        tokens.append(listtokens[i])\r\n",
    "        for index,word in enumerate(tokens):\r\n",
    "            word_to_index[word]=index+2\r\n",
    "            index_to_word[index+2]=word\r\n",
    "        self.word_to_index=word_to_index\r\n",
    "        self.index_to_word=index_to_word\r\n",
    "\r\n",
    "    def fit_on_text2(self,data):\r\n",
    "        word_to_index={}\r\n",
    "        index_to_word={}\r\n",
    "        word_to_index[\"<PAD>\"]=0\r\n",
    "        word_to_index[\"<OOV>\"]=1\r\n",
    "        index_to_word[0]=\"<PAD>\"\r\n",
    "        index_to_word[1]=\"<OOV>\"\r\n",
    "        myContinue=False\r\n",
    "        tokens=[]\r\n",
    "        for eachseq in data:\r\n",
    "            listtokens=eachseq.lower().split(\" \")\r\n",
    "            listtokens.append(\"\")\r\n",
    "            for i in range(0,len(listtokens)-1):\r\n",
    "                if (listtokens[i+1]!=\"\"):\r\n",
    "                    pairtext=listtokens[i]+\"_\"+listtokens[i+1]\r\n",
    "                    if (self.bi_gram_checker(pairtext)):\r\n",
    "                        if (tokens.count(pairtext)==0):\r\n",
    "                            tokens.append(pairtext)\r\n",
    "                if (tokens.count(listtokens[i])==0 and listtokens[i]!=\"\"):\r\n",
    "                    tokens.append(listtokens[i])\r\n",
    "        for index,word in enumerate(tokens):\r\n",
    "            word_to_index[word]=index+2\r\n",
    "            index_to_word[index+2]=word\r\n",
    "        self.word_to_index=word_to_index\r\n",
    "        self.index_to_word=index_to_word\r\n",
    "    \r\n",
    "    def get_word_to_index(self):\r\n",
    "        return self.word_to_index\r\n",
    "    \r\n",
    "    def get_index_to_word(self):\r\n",
    "        return self.index_to_word\r\n",
    "\r\n",
    "    def get_max_length(self,data):\r\n",
    "        maxsen=0\r\n",
    "        for i in data:\r\n",
    "            if maxsen<len(i):\r\n",
    "                maxsen=len(i)\r\n",
    "        return maxsen\r\n",
    "\r\n",
    "    def text_to_sequence(self,textdata):\r\n",
    "        d_continue=False\r\n",
    "        output=[]\r\n",
    "        for text in textdata:\r\n",
    "            text=text.lower().split(\" \")\r\n",
    "            text.append(\"\")\r\n",
    "            sth=[]\r\n",
    "            d_continue=False\r\n",
    "            for i in range(0,len(text)-1):\r\n",
    "                if d_continue==True:\r\n",
    "                    d_continue=False\r\n",
    "                    continue\r\n",
    "                if (text[i+1]!=\"\"):\r\n",
    "                    pairtext=text[i]+\"_\"+text[i+1]\r\n",
    "                    for j in self.word_to_index:\r\n",
    "                        if pairtext.lower()==j:\r\n",
    "                            sth.append(self.word_to_index[j])\r\n",
    "                            d_continue=True\r\n",
    "                            break\r\n",
    "                if d_continue==False:\r\n",
    "                    for count,j in enumerate(self.word_to_index):\r\n",
    "                        if text[i].lower()==j:\r\n",
    "                            sth.append(self.word_to_index[j])\r\n",
    "                            break\r\n",
    "                        if count==len(self.word_to_index)-1:\r\n",
    "                            sth.append(1)\r\n",
    "            output.append(sth)\r\n",
    "        return output\r\n",
    "    \r\n",
    "    def intseq_to_index(self,sequence):\r\n",
    "        output=[]\r\n",
    "        for i in sequence:\r\n",
    "            output.append(self.index_to_word[i])\r\n",
    "        return output\r\n",
    "\r\n",
    "    def pad_sequence(self,datasequence,maxlen):\r\n",
    "        for i in datasequence:\r\n",
    "            while len(i)!=maxlen:\r\n",
    "                i.insert(0,0)\r\n",
    "        return datasequence\r\n",
    "\r\n",
    "    def bi_gram_ize(self,text):\r\n",
    "        listtokens=text.lower().split(\" \")\r\n",
    "        listtokens.append(\"\")\r\n",
    "        myContinue=False\r\n",
    "        tokens=[]\r\n",
    "        for i in range(0,len(listtokens)-1):\r\n",
    "            if (myContinue):\r\n",
    "                myContinue=False\r\n",
    "                continue\r\n",
    "            if (listtokens[i+1]!=\"\"):\r\n",
    "                pairtext=listtokens[i]+\"_\"+listtokens[i+1]\r\n",
    "                if (self.bi_gram_checker(pairtext)):\r\n",
    "                    myContinue=True\r\n",
    "                    if (tokens.count(pairtext)==0):\r\n",
    "                        tokens.append(pairtext)\r\n",
    "            if (myContinue==False):  \r\n",
    "                if (tokens.count(listtokens[i])==0):\r\n",
    "                    tokens.append(listtokens[i])\r\n",
    "        return tokens\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "myTokenizer=FTokenizer(t)\r\n",
    "myTokenizer.fit_on_text2(rsen)\r\n",
    "seqTokenized2=myTokenizer.text_to_sequence(rsen)\r\n",
    "test_seqTokenized2=myTokenizer.text_to_sequence(test_rsen)\r\n",
    "final_seq2=tf.keras.preprocessing.sequence.pad_sequences(seqTokenized2)\r\n",
    "mlen2=final_seq2.shape[1]\r\n",
    "final_test_seq2=tf.keras.preprocessing.sequence.pad_sequences(test_seqTokenized2,maxlen=final_seq2.shape[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# num_tokens = len(myTokenizer.word_to_index)\r\n",
    "# embedding_dim = 128\r\n",
    "# hits = 0\r\n",
    "# misses = 0\r\n",
    "\r\n",
    "# # Prepare embedding matrix\r\n",
    "# embedding_matrix = np.zeros((num_tokens, embedding_dim))\r\n",
    "# for word, i in myTokenizer.word_to_index.items():\r\n",
    "#     embedding_vector = vocab_weights.get(word)\r\n",
    "#     if embedding_vector is not None:\r\n",
    "#         # Words not found in embedding index will be all-zeros.\r\n",
    "#         # This includes the representation for \"padding\" and \"OOV\"\r\n",
    "#         embedding_matrix[i] = embedding_vector\r\n",
    "#         hits += 1\r\n",
    "#     else:\r\n",
    "#         misses += 1\r\n",
    "# print(\"Converted %d words (%d misses)\" % (hits, misses))\r\n",
    "\r\n",
    "# embedding_layer = tf.keras.layers.Embedding(\r\n",
    "#     num_tokens,\r\n",
    "#     embedding_dim,\r\n",
    "#     embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\r\n",
    "#     trainable=False,\r\n",
    "# )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def LSTMModel():\r\n",
    "    inputs=tf.keras.layers.Input(shape=(maxseqlen,),dtype=\"int32\")\r\n",
    "    embedding=tf.keras.layers.Embedding(len(VNTokenizer.word_index)+1,128)(inputs)\r\n",
    "    # embedding=embedding_layer(inputs)\r\n",
    "    bilstmlayer=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True))(embedding)\r\n",
    "    dense=tf.keras.layers.Dense(16,activation=\"relu\")(bilstmlayer)\r\n",
    "    output=tf.keras.layers.Dense(len(posTokenizer.word_index)+1,activation=\"softmax\")(dense)\r\n",
    "    return tf.keras.Model(inputs,output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_test_pos.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(722, 71)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "myModel=LSTMModel()\r\n",
    "myModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=\"sparse_categorical_crossentropy\",metrics=[\"sparse_categorical_accuracy\"])\r\n",
    "myModel.fit(final_seq,final_pos,batch_size=64,epochs=100,validation_data=(final_test_seq,final_test_pos))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 13s 165ms/step - loss: 0.8275 - sparse_categorical_accuracy: 0.8055 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8737\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 10s 160ms/step - loss: 0.4035 - sparse_categorical_accuracy: 0.8755 - val_loss: 0.3991 - val_sparse_categorical_accuracy: 0.8743\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 10s 160ms/step - loss: 0.3661 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.3707 - val_sparse_categorical_accuracy: 0.8745\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 10s 161ms/step - loss: 0.3197 - sparse_categorical_accuracy: 0.8790 - val_loss: 0.3080 - val_sparse_categorical_accuracy: 0.8871\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 10s 159ms/step - loss: 0.2397 - sparse_categorical_accuracy: 0.9212 - val_loss: 0.2420 - val_sparse_categorical_accuracy: 0.9391\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 10s 163ms/step - loss: 0.1658 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.1948 - val_sparse_categorical_accuracy: 0.9516\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 10s 162ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9755 - val_loss: 0.1664 - val_sparse_categorical_accuracy: 0.9597\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 10s 161ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9630\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 10s 160ms/step - loss: 0.0736 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1504 - val_sparse_categorical_accuracy: 0.9646\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 10s 162ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9838 - val_loss: 0.1515 - val_sparse_categorical_accuracy: 0.9643\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 10s 160ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9848 - val_loss: 0.1529 - val_sparse_categorical_accuracy: 0.9649\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.1537 - val_sparse_categorical_accuracy: 0.9644\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.1569 - val_sparse_categorical_accuracy: 0.9647\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.1609 - val_sparse_categorical_accuracy: 0.9643\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0464 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.1642 - val_sparse_categorical_accuracy: 0.9642\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9890 - val_loss: 0.1710 - val_sparse_categorical_accuracy: 0.9634\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.1724 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 9s 149ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.1837 - val_sparse_categorical_accuracy: 0.9635\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 0.0352 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.1835 - val_sparse_categorical_accuracy: 0.9625\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 0.0327 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.1879 - val_sparse_categorical_accuracy: 0.9633\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 0.0299 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.1994 - val_sparse_categorical_accuracy: 0.9623\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 9s 152ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.2014 - val_sparse_categorical_accuracy: 0.9618\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9616\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.2140 - val_sparse_categorical_accuracy: 0.9613\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.2292 - val_sparse_categorical_accuracy: 0.9615\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.2308 - val_sparse_categorical_accuracy: 0.9612\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.2292 - val_sparse_categorical_accuracy: 0.9605\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.2378 - val_sparse_categorical_accuracy: 0.9601\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.2474 - val_sparse_categorical_accuracy: 0.9600\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.2613 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.2643 - val_sparse_categorical_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.2703 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.2817 - val_sparse_categorical_accuracy: 0.9593\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 9s 142ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.2889 - val_sparse_categorical_accuracy: 0.9596\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.9594\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 9s 142ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.3032 - val_sparse_categorical_accuracy: 0.9593\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.3068 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 9s 149ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.9583\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 10s 155ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.3185 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 9s 149ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.3358 - val_sparse_categorical_accuracy: 0.9597\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.3417 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.3530 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.3574 - val_sparse_categorical_accuracy: 0.9585\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.3670 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.3683 - val_sparse_categorical_accuracy: 0.9579\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.3763 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.3784 - val_sparse_categorical_accuracy: 0.9581\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 9.8308e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.3912 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 8.6301e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.3925 - val_sparse_categorical_accuracy: 0.9580\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 8.4987e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.3902 - val_sparse_categorical_accuracy: 0.9578\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 10s 157ms/step - loss: 9.1021e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.4013 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 9s 150ms/step - loss: 9.2165e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.4121 - val_sparse_categorical_accuracy: 0.9586\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 9s 150ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.4090 - val_sparse_categorical_accuracy: 0.9580\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.3952 - val_sparse_categorical_accuracy: 0.9575\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 9s 149ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.3993 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.3795 - val_sparse_categorical_accuracy: 0.9574\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.3965 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 9s 149ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.4040 - val_sparse_categorical_accuracy: 0.9586\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 7.4062e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4051 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 4.7505e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4136 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 9s 150ms/step - loss: 3.8682e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4183 - val_sparse_categorical_accuracy: 0.9592\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 3.3165e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4228 - val_sparse_categorical_accuracy: 0.9592\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 2.9369e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4275 - val_sparse_categorical_accuracy: 0.9591\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 2.6373e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4289 - val_sparse_categorical_accuracy: 0.9591\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 2.3983e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4335 - val_sparse_categorical_accuracy: 0.9592\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 2.1781e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.9591\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 2.0060e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4404 - val_sparse_categorical_accuracy: 0.9591\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 1.8313e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.9590\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 1.6932e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4452 - val_sparse_categorical_accuracy: 0.9591\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 1.5807e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4478 - val_sparse_categorical_accuracy: 0.9590\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 1.4633e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4520 - val_sparse_categorical_accuracy: 0.9591\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 9s 149ms/step - loss: 1.3674e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4544 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 1.2759e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 1.1978e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4591 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 1.1218e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 9s 150ms/step - loss: 1.0539e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 9.9495e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 10s 154ms/step - loss: 9.3811e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4694 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 8.8307e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4716 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 10s 154ms/step - loss: 8.3761e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 10s 157ms/step - loss: 7.9340e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 7.5378e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4788 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 7.1303e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4817 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 9s 149ms/step - loss: 6.7664e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4818 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 6.4266e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4848 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 6.0849e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 5.8072e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4885 - val_sparse_categorical_accuracy: 0.9589\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 5.4996e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4908 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 5.2377e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4929 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 4.9960e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4958 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 4.7580e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4976 - val_sparse_categorical_accuracy: 0.9586\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 4.5377e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4992 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 4.3341e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5010 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 4.1467e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5036 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 9s 146ms/step - loss: 3.9565e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5062 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 3.7810e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5075 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 3.6112e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5094 - val_sparse_categorical_accuracy: 0.9586\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 3.4608e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5117 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 9s 145ms/step - loss: 3.3214e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5133 - val_sparse_categorical_accuracy: 0.9585\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10294bcedf0>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_seq.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1969, 71)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "VNTokenizer.index_word[0]=\"<PAD>\"\r\n",
    "def insert_text(inp):\r\n",
    "    inp_gramized=myTokenizer.bi_gram_ize(inp)\r\n",
    "    inp_tokenized=VNTokenizer.texts_to_sequences([inp_gramized])\r\n",
    "    final_inp=tf.keras.preprocessing.sequence.pad_sequences(inp_tokenized,maxlen=maxseqlen)\r\n",
    "    return final_inp\r\n",
    "insert_text(\"Hôm nay quan trọng lắm đó\").shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 71)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 69)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "execution_count": 87,
>>>>>>> d0f83f4dc4e1db072f7be0520b77de864bcee40f
   "source": [
    "myModel.save(\"D:/a-Code/Ignite Niek/foxPython/NewTagger/PosTaggerModel\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: D:/a-Code/Ignite Niek/foxPython/NewTagger/PosTaggerModel\\assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: D:/a-Code/Ignite Niek/foxPython/NewTagger/PosTaggerModel\\assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "posTokenizer.index_word"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: 'noun',\n",
       " 2: 'verb',\n",
       " 3: 'x',\n",
       " 4: 'adp',\n",
       " 5: 'adj',\n",
       " 6: 'propn',\n",
       " 7: 'num',\n",
       " 8: 'cconj',\n",
       " 9: 'det',\n",
       " 10: 'sconj',\n",
       " 11: 'aux',\n",
       " 12: 'part',\n",
       " 13: 'intj'}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "posTokenizer.index_word[0]=\"<PAD>\"\r\n",
    "posPred=myModel.predict(insert_text(\"Phim bạn yêu thích là gì\"))\r\n",
    "np.round(posPred[0],decimals=2)\r\n",
    "for i in posPred[0]:\r\n",
    "    print(posTokenizer.index_word[np.argmax(i)],end=\" \")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 71), found shape=(None, 69)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f6ba9e2b8d95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mposTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"<PAD>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mposPred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsert_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Phim bạn yêu thích là gì\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposPred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mposPred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 71), found shape=(None, 69)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}